import os
import json
import asyncio
import random
import re
import time
import hashlib
import html
import urllib.parse
import tempfile
import shutil
import logging
from dataclasses import dataclass
from typing import Literal, Optional
from difflib import SequenceMatcher

import aiohttp
import feedparser
from youtube_transcript_api import YouTubeTranscriptApi
from aiogram import Bot
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.types import FSInputFile
from groq import Groq, RateLimitError, APIError

# ============ –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ============

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger("KiberSOS")

# ============ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ============

def get_env(name: str) -> str:
    val = os.getenv(name)
    if not val:
        logger.error(f"Missing: {name}")
        exit(1)
    return val

GROQ_API_KEY = get_env("GROQ_API_KEY")
TELEGRAM_BOT_TOKEN = get_env("TELEGRAM_BOT_TOKEN")
CHANNEL_ID = get_env("CHANNEL_ID")

CACHE_DIR = os.getenv("CACHE_DIR", "cache_sec")
os.makedirs(CACHE_DIR, exist_ok=True)
STATE_FILE = os.path.join(CACHE_DIR, "state_groq_v2.json")

TEXT_ONLY_THRESHOLD = 700
MAX_POSTED_IDS = 400
HTTP_TIMEOUT = aiohttp.ClientTimeout(total=25)
IMAGE_TIMEOUT = aiohttp.ClientTimeout(total=40)

# ============ –û–ë–ù–û–í–õ–ï–ù–ù–´–ï –ú–û–î–ï–õ–ò ============

@dataclass
class ModelConfig:
    name: str
    rpm: int
    tpm: int
    daily_tokens: int
    priority: int

MODELS = {
    "heavy": ModelConfig("llama-3.3-70b-versatile", rpm=30, tpm=6000, daily_tokens=100000, priority=1),
    "light": ModelConfig("llama-3.1-8b-instant", rpm=30, tpm=20000, daily_tokens=500000, priority=2),
    "fallback": ModelConfig("mixtral-8x7b-32768", rpm=30, tpm=5000, daily_tokens=100000, priority=3),
}

class GroqBudget:
    def __init__(self):
        self.state_file = os.path.join(CACHE_DIR, "groq_budget.json")
        self.data = self._load()
    
    def _load(self) -> dict:
        default = {
            "daily_tokens": {},
            "last_reset": time.strftime("%Y-%m-%d"),
            "last_request_time": {},
            "request_count": {},
            "minute_start": {},
        }
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, "r") as f:
                    saved = json.load(f)
                    if saved.get("last_reset") != time.strftime("%Y-%m-%d"):
                        logger.info("üîÑ –ù–æ–≤—ã–π –¥–µ–Ω—å ‚Äî —Å–±—Ä–æ—Å –ª–∏–º–∏—Ç–æ–≤ Groq")
                        saved["daily_tokens"] = {}
                        saved["last_reset"] = time.strftime("%Y-%m-%d")
                    default.update(saved)
            except: pass
        return default
    
    def save(self):
        try:
            with open(self.state_file, "w") as f: json.dump(self.data, f)
        except: pass
    
    def add_tokens(self, model: str, tokens: int):
        self.data["daily_tokens"][model] = self.data["daily_tokens"].get(model, 0) + tokens
        self.save()
    
    def can_use_model(self, model_key: str) -> bool:
        if model_key not in MODELS: return False
        cfg = MODELS[model_key]
        used = self.data["daily_tokens"].get(cfg.name, 0)
        return (cfg.daily_tokens - used) > (cfg.daily_tokens * 0.05)
    
    async def wait_for_rate_limit(self, model_key: str):
        cfg = MODELS[model_key]
        model = cfg.name
        now = time.time()
        
        if now - self.data["minute_start"].get(model, 0) > 60:
            self.data["minute_start"][model] = now
            self.data["request_count"][model] = 0
        
        if self.data["request_count"].get(model, 0) >= cfg.rpm - 2:
            wait = 60 - (now - self.data["minute_start"][model]) + 1
            logger.info(f"‚è≥ –õ–∏–º–∏—Ç RPM ({model_key}). –ñ–¥–µ–º {wait:.1f}—Å")
            await asyncio.sleep(wait)
            self.data["minute_start"][model] = time.time()
            self.data["request_count"][model] = 0
            
        last = self.data["last_request_time"].get(model, 0)
        if now - last < 2: await asyncio.sleep(2)
        
        self.data["request_count"][model] = self.data["request_count"].get(model, 0) + 1
        self.data["last_request_time"][model] = time.time()

budget = GroqBudget()

# ============ –§–ò–õ–¨–¢–†–´ ============

# –°—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
STOP_WORDS = [
    "headphone", "jbl", "bluetooth headset", "earbuds",
    "quarterly earnings", "appointed ceo", "marketing campaign", "conference announcement",
    "cryptocurrency", "casino", "gambling", "nft trading", "bitcoin price"
]

# –ë–∞–Ω–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã –Ω–∞ –†–£–°–°–ö–û–ú (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ—Å—Ç–∞)
BANNED_PHRASES = [
    "–∏–∑ –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤", "—Ä–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è–π—Ç–µ", "–±—É–¥—å—Ç–µ –±–¥–∏—Ç–µ–ª—å–Ω—ã",
    "–≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —á–∏—Ç–∞–π—Ç–µ", "–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å", "–Ω–∞–¥—ë–∂–Ω—ã–π –ø–∞—Ä–æ–ª—å",
    "–Ω–µ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –ø–æ —Å—Å—ã–ª–∫–∞–º", "–±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã", "–ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Å—Å—ã–ª–∫–∏",
    "—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è", "–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–≤—É—Ö—Ñ–∞–∫—Ç–æ—Ä–Ω—É—é", "—Å–ª–æ–∂–Ω—ã–µ –ø–∞—Ä–æ–ª–∏",
    "–Ω–∞–¥–µ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è", "—Å–∏—Å—Ç–µ–º—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è", "–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ç—Ä–∞—Ñ–∏–∫–∞",
    "–æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", "–∑–∞—â–∏—Ç–∏—Ç—å —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ", "–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∞—Ç–∞–∫",
    "—É—Å—Ç—Ä–∞–Ω—è—Ç—å —É—è–∑–≤–∏–º–æ—Å—Ç–∏", "–∑–ª–æ—É–º—ã—à–ª–µ–Ω–Ω–∏–∫–∞–º–∏ –¥–ª—è –∞—Ç–∞–∫", "—Å–æ–±–ª—é–¥–∞–π—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å",
    "–±–∞–∑–æ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞", "–∫–∏–±–µ—Ä–≥–∏–≥–∏–µ–Ω", "–Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–π—Ç–µ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ",
    "–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–∞–¥–µ–∂–Ω", "—Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ", "–æ–±—É—á–µ–Ω–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤",
    "–ø–æ–≤—ã—à–µ–Ω–∏–µ –æ—Å–≤–µ–¥–æ–º–ª–µ–Ω–Ω–æ—Å—Ç–∏", "–∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–æ–¥—Ö–æ–¥", "–º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –∑–∞—â–∏—Ç–∞"
]

# –°–ò–õ–¨–ù–´–ï —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (–∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞)
STRONG_TECH_INDICATORS = [
    "cve-", "0day", "zero-day", "exploit", "payload", "backdoor", "trojan",
    "ransomware", "apt28", "apt29", "lazarus", "sandworm", "fancy bear",
    "cozy bear", "killnet", "lockbit", "blackcat", "alphv", "conti",
    ".exe", ".dll", ".apk", ".ps1", ".bat", ".sh", ".vbs",
    "powershell", "mimikatz", "cobalt strike", "metasploit", "nmap",
    "c2 server", "c&c", "command and control", "reverse shell",
    "sql injection", "xss", "csrf", "rce", "lpe", "privilege escalation",
    "buffer overflow", "heap spray", "use-after-free", "race condition",
    "–ø–æ—Ä—Ç 445", "–ø–æ—Ä—Ç 3389", "–ø–æ—Ä—Ç 22", "–ø–æ—Ä—Ç 80", "–ø–æ—Ä—Ç 443",
    "smb", "rdp", "ssh", "ftp", "telnet", "vnc",
    "lateral movement", "persistence", "exfiltration", "c2 beacon"
]

# –û–±—ã—á–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã (–¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞)
TECH_INDICATORS = [
    "cve-", "0day", "exploit", "payload", "shell", "sudo", "root",
    "dns", "ssh", "rdp", "smb", "api", "token", "hash", "aes", "rsa", "tls", "ssl",
    "android", "ios", "windows", "linux", "macos",
    "chrome", "firefox", "safari", "edge", "telegram", "whatsapp",
    "apt", "phishing", "malware", "ransomware", "backdoor", "trojan",
    "–≤—Ä–µ–¥–æ–Ω–æ—Å", "—ç–∫—Å–ø–ª–æ–π—Ç", "—É—è–∑–≤–∏–º–æ—Å—Ç", "—Ñ–∏—à–∏–Ω–≥", "—Ö–∞–∫–µ—Ä", "–≤–∑–ª–æ–º",
    "—É—Ç–µ—á–∫", "–±—Ä–µ—à—å", "–ø–∞—Ç—á", "–æ–±–Ω–æ–≤–ª–µ–Ω–∏"
]


def is_too_generic(text: str) -> bool:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –†–£–°–°–ö–û–ì–û –ø–æ—Å—Ç–∞ –Ω–∞ –±–∞–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
    text_lower = text.lower()
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–Ω–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑ (–ø–æ—Ä–æ–≥ 2+)
    banned_count = sum(1 for phrase in BANNED_PHRASES if phrase in text_lower)
    if banned_count >= 2:
        logger.info(f"‚ö†Ô∏è Too many generic phrases: {banned_count}")
        return True
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –°–ò–õ–¨–ù–´–ï —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
    strong_tech = sum(1 for t in STRONG_TECH_INDICATORS if t in text_lower)
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–µ—Ä—Å–∏–∏/–Ω–æ–º–µ—Ä–∞/CVE
    has_version = bool(re.search(r'\d+\.\d+\.\d+', text))  # –í–µ—Ä—Å–∏—è —Ç–∏–ø–∞ 1.2.3
    has_cve = bool(re.search(r'CVE-\d{4}-\d+', text, re.I))  # CVE-2024-12345
    has_port = bool(re.search(r'–ø–æ—Ä—Ç\s*\d+', text_lower))  # –ø–æ—Ä—Ç 445
    has_ip = bool(re.search(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}', text))  # IP –∞–¥—Ä–µ—Å
    has_path = bool(re.search(r'[A-Z]:\\|/etc/|/var/|/tmp/', text))  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
    has_command = bool(re.search(r'(sudo|chmod|chown|netsh|reg add|powershell|cmd)', text_lower))  # –ö–æ–º–∞–Ω–¥—ã
    has_hash = bool(re.search(r'[a-f0-9]{32,64}', text_lower))  # MD5/SHA —Ö–µ—à
    
    specifics_count = sum([has_version, has_cve, has_port, has_ip, has_path, has_command, has_hash])
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
    if specifics_count == 0 and strong_tech < 2:
        logger.info(f"‚ö†Ô∏è No specific details (versions/CVE/ports/paths): strong_tech={strong_tech}")
        return True
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å 1 –±–∞–Ω–∞–ª—å–Ω–∞—è —Ñ—Ä–∞–∑–∞, —Ç—Ä–µ–±—É–µ–º –±–æ–ª—å—à–µ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏
    if banned_count == 1 and specifics_count == 0 and strong_tech < 3:
        logger.info(f"‚ö†Ô∏è Has generic phrase but lacks specifics")
        return True
    
    # 4. –û–±—â–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã (–º—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
    tech_count = sum(1 for term in TECH_INDICATORS if term in text_lower)
    if tech_count < 2:
        logger.info(f"‚ö†Ô∏è Not enough technical terms: {tech_count}/2")
        return True
    
    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–∑–±—ã—Ç–æ–∫ —Å–æ–≤–µ—Ç–æ–≤-—Å–ø–∏—Å–∫–æ–≤
    lines = [l for l in text.split('\n') if l.strip()]
    advice_lines = [l for l in lines if l.strip().startswith(('‚Ä¢', '-', '‚úì', '‚Äî', '‚Äì'))]
    if len(advice_lines) >= 4 and len(lines) > 0:
        if len(advice_lines) / len(lines) > 0.5:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ —Å–æ–≤–µ—Ç–∞—Ö –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞
            advice_text = ' '.join(advice_lines).lower()
            advice_has_specifics = (
                bool(re.search(r'\d+\.\d+', advice_text)) or
                bool(re.search(r'cve-', advice_text)) or
                bool(re.search(r'–ø–æ—Ä—Ç\s*\d+', advice_text)) or
                any(t in advice_text for t in STRONG_TECH_INDICATORS[:20])
            )
            if not advice_has_specifics:
                logger.info(f"‚ö†Ô∏è Too many generic tips without specifics: {len(advice_lines)} lines")
                return True
    
    # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –ø–æ–ª–µ–∑–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏, –ø—Ä–æ–±–µ–ª—ã, —Å—Å—ã–ª–∫–∏
    clean_text = re.sub(r'[^\w\s]', '', text)
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    words = clean_text.split()
    if len(words) < 30:
        logger.info(f"‚ö†Ô∏è Post too short: {len(words)} words")
        return True
    
    logger.info(f"‚úÖ Post passed quality check: {specifics_count} specifics, {strong_tech} strong terms, {banned_count} banned phrases")
    return False


def passes_local_filters(title: str, text: str) -> bool:
    """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ê–ù–ì–õ–ò–ô–°–ö–û–ì–û –∏—Å—Ö–æ–¥–Ω–∏–∫–∞"""
    content = (title + " " + text).lower()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤
    if any(w in content for w in STOP_WORDS):
        logger.info(f"üö´ Stop word found: {title[:50]}...")
        return False
    
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
    if len(text) < 100:
        return False
    
    # –¢—Ä–µ–±—É–µ–º –Ω–∞–ª–∏—á–∏–µ security-–∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Ç–µ–∫—Å—Ç–µ
    security_keywords = [
        "vulnerability", "exploit", "malware", "ransomware", "phishing",
        "hacker", "breach", "attack", "threat", "zero-day", "patch",
        "security", "cybersecurity", "cyber attack", "data breach",
        "cve-", "backdoor", "trojan", "apt", "intrusion", "compromise"
    ]
    if not any(kw in content for kw in security_keywords):
        logger.info(f"üö´ No security keywords: {title[:50]}...")
        return False
    
    return True


# ============ GROQ CALLER ============

async def call_groq(prompt: str, model_pref: str = "heavy", max_tokens: int = 1500) -> tuple[str, int]:
    order = ["heavy", "light", "fallback"] if model_pref == "heavy" else ["light", "fallback", "heavy"]
    
    for key in order:
        if not budget.can_use_model(key): continue
        cfg = MODELS[key]
        
        try:
            await budget.wait_for_rate_limit(key)
            response = await asyncio.to_thread(
                lambda: groq_client.chat.completions.create(
                    model=cfg.name,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=max_tokens
                )
            )
            res = response.choices[0].message.content.strip()
            tokens = response.usage.total_tokens if response.usage else 0
            budget.add_tokens(cfg.name, tokens)
            logger.info(f"‚úÖ Model used: {cfg.name} ({tokens} tokens)")
            return res, tokens
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error {key} ({cfg.name}): {e}")
            await asyncio.sleep(5)
            continue
            
    return "", 0


# ============ –õ–û–ì–ò–ö–ê ============

async def check_duplicate(new_title: str, recent: list) -> bool:
    if not recent: return False
    
    norm_new = re.sub(r'\W', '', new_title.lower())
    for old in recent[-20:]:
        norm_old = re.sub(r'\W', '', old.lower())
        if SequenceMatcher(None, norm_new, norm_old).ratio() > 0.6:
            logger.info(f"üîÑ Local duplicate: {new_title[:50]}...")
            return True
            
    history = "\n".join(f"- {t}" for t in recent[-10:])
    prompt = f"–¢–µ–º—ã:\n{history}\n\n–ù–æ–≤–∞—è: '{new_title}'\n–î—É–±–ª–∏–∫–∞—Ç? YES/NO"
    ans, _ = await call_groq(prompt, "light", 10)
    
    return "YES" in ans.upper()


async def generate_post(item) -> Optional[str]:
    prompt = f"""–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–≥–æ Telegram-–∫–∞–Ω–∞–ª–∞ –ø—Ä–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å (30–∫+ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤).

–ò–°–•–û–î–ù–ê–Ø –ù–û–í–û–°–¢–¨ (English):
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {item.title}
–¢–µ–∫—Å—Ç: {item.text[:2500]}

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
1. –ü—Ä–æ—á–∏—Ç–∞–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç –∏ –ø–µ—Ä–µ–≤–µ–¥–∏ —Å—É—Ç—å –Ω–∞ –†–£–°–°–ö–ò–ô —è–∑—ã–∫
2. –ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –Ω–∞ –†–£–°–°–ö–û–ú —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –¥–µ—Ç–∞–ª—è–º–∏

–°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê:
‚ùå –ó–ê–ü–†–ï–©–ï–ù–û –ø–∏—Å–∞—Ç—å –±–∞–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:
   - "—Ä–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è–π—Ç–µ –ü–û" (–±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≤–µ—Ä—Å–∏–∏)
   - "–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å", "–±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã"
   - "–Ω–∞–¥–µ–∂–Ω—ã–µ –ø–∞—Ä–æ–ª–∏", "–¥–≤—É—Ö—Ñ–∞–∫—Ç–æ—Ä–Ω–∞—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è"
   - "—Å–∏—Å—Ç–µ–º—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è", "–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ç—Ä–∞—Ñ–∏–∫–∞"
   - "–∑–∞—â–∏—Ç–∏—Ç—å —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ", "—Å–æ–±–ª—é–¥–∞–π—Ç–µ –∫–∏–±–µ—Ä–≥–∏–≥–∏–µ–Ω—É"
   - "–æ–±—É—á–µ–Ω–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤", "–ø–æ–≤—ã—à–µ–Ω–∏–µ –æ—Å–≤–µ–¥–æ–º–ª–µ–Ω–Ω–æ—Å—Ç–∏"

‚úÖ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–∫–ª—é—á–∏ –ö–û–ù–ö–†–ï–¢–ò–ö–£:
   - CVE-–Ω–æ–º–µ—Ä–∞ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π (CVE-2024-XXXXX)
   - –¢–æ—á–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ —Å–æ—Ñ—Ç–∞ (Chrome 131.0.6778.264, Windows 11 23H2)
   - –ù–æ–º–µ—Ä–∞ –ø–æ—Ä—Ç–æ–≤ (–ø–æ—Ä—Ç 445, –ø–æ—Ä—Ç 3389)
   - –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º (C:\\Windows\\Temp\\evil.dll, /etc/passwd)
   - –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏/–∑–∞—â–∏—Ç—ã (netsh, powershell, grep)
   - –ù–∞–∑–≤–∞–Ω–∏—è –º–∞–ª–≤–∞—Ä–∏/–≥—Ä—É–ø–ø (LockBit, APT29, Cobalt Strike)
   - IP-–∞–¥—Ä–µ—Å–∞ –∏–ª–∏ –¥–æ–º–µ–Ω—ã (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ)
   - –•–µ—à–∏ —Ñ–∞–π–ª–æ–≤ (MD5/SHA256, –µ—Å–ª–∏ –µ—Å—Ç—å)

üìå –ï—Å–ª–∏ –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ –ù–ï–¢ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π ‚Äî –ø–∏—à–∏ SKIP

–§–û–†–ú–ê–¢ –ü–û–°–¢–ê (–Ω–∞ –†–£–°–°–ö–û–ú):
üî• [–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –≤–µ—Ä—Å–∏–µ–π/CVE/–Ω–∞–∑–≤–∞–Ω–∏–µ–º —É–≥—Ä–æ–∑—ã]

[2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –ß–¢–û –ø—Ä–æ–∏–∑–æ—à–ª–æ + —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –∞—Ç–∞–∫–∏]

üëá –ß–¢–û –°–î–ï–õ–ê–¢–¨:
‚Ä¢ [–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ —Å –≤–µ—Ä—Å–∏–µ–π/–∫–æ–º–∞–Ω–¥–æ–π/–ø—É—Ç—ë–º]
‚Ä¢ [–ï—â—ë –æ–¥–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ]

–ü–†–ò–ú–ï–†–´ –•–û–†–û–®–ï–ì–û –ü–û–°–¢–ê:
‚úÖ "–û–±–Ω–æ–≤–∏—Ç–µ Chrome –¥–æ 131.0.6778.108 ‚Äî –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ CVE-2024-12692 (RCE —á–µ—Ä–µ–∑ V8)"
‚úÖ "–ó–∞–±–ª–æ–∫–∏—Ä—É–π—Ç–µ –ø–æ—Ä—Ç 445: netsh advfirewall firewall add rule name='Block SMB' dir=in action=block protocol=TCP localport=445"
‚úÖ "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ C:\\Windows\\Temp\\svchost.exe (–Ω–µ –ø—É—Ç–∞—Ç—å —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º)"
‚úÖ "APT29 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Cobalt Strike —Å C2 –Ω–∞ –¥–æ–º–µ–Ω–µ evil.example[.]com"

–ü–†–ò–ú–ï–†–´ –ü–õ–û–•–û–ì–û (–ù–ï –ü–ò–°–ê–¢–¨ –¢–ê–ö):
‚ùå "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–∞–¥–µ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–µ—Ç–∏"
‚ùå "–†–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è–π—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ"  
‚ùå "–ë—É–¥—å—Ç–µ –±–¥–∏—Ç–µ–ª—å–Ω—ã –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –ø–æ —Å—Å—ã–ª–∫–∞–º"
‚ùå "–ü—Ä–æ–≤–æ–¥–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"

–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ –∏–ª–∏ SKIP:"""

    text, _ = await call_groq(prompt, "heavy", 1200)
    
    if not text or "SKIP" in text.upper() or len(text) < 120:
        logger.info("‚è© AI returned SKIP or too short")
        return None
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–∞–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    if is_too_generic(text):
        logger.info(f"‚è© Post rejected: too generic")
        return None
        
    return text + f"\n\nüîó <a href='{item.link}'>–ò—Å—Ç–æ—á–Ω–∏–∫</a>"


# ============ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø ============

async def generate_image(title, session):
    try:
        styles = ["cyberpunk neon red", "matrix green code", "hacker terminal glitch", "dark web aesthetic"]
        clean_t = re.sub(r'[^a-zA-Z0-9\s]', '', title)[:40]
        prompt = f"hacker silhouette keyboard, {clean_t}, {random.choice(styles)}, dark background"
        encoded = urllib.parse.quote(prompt)
        url = f"https://image.pollinations.ai/prompt/{encoded}?width=1280&height=720&nologo=true&seed={random.randint(0,99999)}"
        
        async with session.get(url, timeout=IMAGE_TIMEOUT) as resp:
            if resp.status == 200:
                data = await resp.read()
                if len(data) > 5000:
                    path = os.path.join(CACHE_DIR, f"img_{int(time.time())}.jpg")
                    with open(path, "wb") as f: f.write(data)
                    logger.info(f"   üñº Image saved: {len(data)} bytes")
                    return path
    except Exception as e:
        logger.warning(f"   ‚ö†Ô∏è Image generation failed: {e}")
    return None


# ============ –ö–õ–ê–°–°–´ ============

@dataclass
class NewsItem:
    type: Literal["news", "video"]
    title: str
    text: str
    link: str
    source: str
    uid: str

bot = Bot(token=TELEGRAM_BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
groq_client = Groq(api_key=GROQ_API_KEY)


# ============ STATE ============

class State:
    def __init__(self):
        self.data = {"posted_ids": {}, "recent_titles": []}
        self._load()
    
    def _load(self):
        if os.path.exists(STATE_FILE):
            try:
                with open(STATE_FILE, "r", encoding="utf-8") as f: self.data.update(json.load(f))
            except: pass
    
    def save(self):
        fd, tmp = tempfile.mkstemp(dir=CACHE_DIR, suffix='.json')
        try:
            with os.fdopen(fd, 'w', encoding='utf-8') as f: json.dump(self.data, f)
            shutil.move(tmp, STATE_FILE)
        except: os.unlink(tmp)
    
    def is_posted(self, uid): return uid in self.data["posted_ids"]
    
    def mark_posted(self, uid, title):
        if len(self.data["posted_ids"]) > MAX_POSTED_IDS:
            self.data["posted_ids"] = dict(sorted(self.data["posted_ids"].items(), key=lambda x: x[1])[-300:])
        self.data["posted_ids"][uid] = int(time.time())
        self.data["recent_titles"].append(title)
        if len(self.data["recent_titles"]) > 40: self.data["recent_titles"] = self.data["recent_titles"][-40:]
        self.save()

state = State()


# ============ –°–ë–û–†–©–ò–ö–ò ============

async def fetch_rss(source, session):
    items = []
    try:
        async with session.get(source['url'], timeout=HTTP_TIMEOUT) as resp:
            if resp.status != 200: return []
            text = await resp.text()
        feed = feedparser.parse(text)
        for entry in feed.entries[:5]:
            link = entry.get('link')
            if not link: continue
            uid = hashlib.md5(link.encode()).hexdigest()
            if state.is_posted(uid): continue
            
            title = entry.get('title', '')
            text = clean_text(entry.get("summary", "") or entry.get("description", ""))
            
            if passes_local_filters(title, text):
                items.append(NewsItem("news", title, text, link, source['name'], uid))
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è RSS fetch error ({source['name']}): {e}")
    return items


async def fetch_youtube(channel, session):
    items = []
    try:
        url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel['id']}"
        async with session.get(url, timeout=HTTP_TIMEOUT) as resp:
            if resp.status != 200: return []
            text = await resp.text()
        feed = feedparser.parse(text)
        for entry in feed.entries[:2]:
            vid = entry.get('yt_videoid')
            uid = f"yt_{vid}"
            if state.is_posted(uid): continue
            try:
                ts = await asyncio.to_thread(lambda: YouTubeTranscriptApi.list_transcripts(vid).find_transcript(['en', 'ru']).fetch())
                full = " ".join([t['text'] for t in ts])
                if passes_local_filters(entry.title, full):
                    items.append(NewsItem("video", entry.title, full[:5000], entry.link, f"YouTube {channel['name']}", uid))
            except: pass
    except: pass
    return items


def clean_text(text):
    if not text: return ""
    return html.unescape(re.sub(r'<[^>]+>', ' ', text)).strip()


# ============ MAIN ============

async def main():
    logger.info("üöÄ Starting (Western Sources ‚Üí Russian Posts)")
    
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_rss(s, session) for s in RSS_SOURCES] + [fetch_youtube(c, session) for c in YOUTUBE_CHANNELS]
        results = await asyncio.gather(*tasks)
        all_items = [i for r in results for i in r]
        
        logger.info(f"üì¶ Found {len(all_items)} items after local filters")
        random.shuffle(all_items)
        
        posts_done = 0
        posts_rejected = 0
        MAX_POSTS_PER_RUN = 1
        
        for item in all_items:
            if posts_done >= MAX_POSTS_PER_RUN:
                break
            
            if not budget.can_use_model("light"):
                logger.warning("‚ö†Ô∏è Daily budget exhausted")
                break
            
            logger.info(f"üîç Analyzing: {item.title[:60]}...")
            
            if await check_duplicate(item.title, state.data["recent_titles"]):
                state.mark_posted(item.uid, item.title)
                continue
            
            post_text = await generate_post(item)
            if not post_text:
                state.mark_posted(item.uid, item.title)
                posts_rejected += 1
                logger.info(f"‚è© Rejected ({posts_rejected} total)")
                continue
            
            try:
                if len(post_text) > TEXT_ONLY_THRESHOLD:
                    logger.info("üìú Text only (Long read)")
                    await bot.send_message(CHANNEL_ID, text=post_text)
                else:
                    logger.info("üì∏ Generating image...")
                    img = await generate_image(item.title, session)
                    if img:
                        await bot.send_photo(CHANNEL_ID, photo=FSInputFile(img), caption=post_text)
                        os.remove(img)
                    else:
                        await bot.send_message(CHANNEL_ID, text=post_text)
                
                logger.info("‚úÖ Posted successfully!")
                state.mark_posted(item.uid, item.title)
                posts_done += 1
                
            except Exception as e:
                logger.error(f"Telegram Error: {e}")

        logger.info(f"üìä Summary: {posts_done} posted, {posts_rejected} rejected as generic")

    await bot.session.close()


if __name__ == "__main__":
    # ============ –ó–ê–ü–ê–î–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò (ENGLISH) ============
    RSS_SOURCES = [
        {"name": "BleepingComputer", "url": "https://www.bleepingcomputer.com/feed/"},
        {"name": "The Hacker News", "url": "https://feeds.feedburner.com/TheHackersNews"},
        {"name": "Krebs on Security", "url": "https://krebsonsecurity.com/feed/"},
        {"name": "Dark Reading", "url": "https://www.darkreading.com/rss_simple.asp"},
        {"name": "Threatpost", "url": "https://threatpost.com/feed/"},
        {"name": "Ars Technica Security", "url": "https://arstechnica.com/tag/security/feed/"},
        {"name": "SecurityWeek", "url": "https://www.securityweek.com/feed/"},
    ]
    
    YOUTUBE_CHANNELS = [
        {"name": "John Hammond", "id": "UCVeW9qkBjo3zosnqUbG7CFw"},
        {"name": "NetworkChuck", "id": "UC9x0AN7BWHpXyPic4IQC74Q"},
        {"name": "LiveOverflow", "id": "UClcE-kVhqyiHCcjYwcpfj9w"},
        {"name": "IppSec", "id": "UCa6eh7gCkpPo5XXUDfygQQA"},
        {"name": "ST√ñK", "id": "UCQN2DsjnYH60SFBIA6IkNwg"},
    ]
    
    asyncio.run(main())

import os
import json
import asyncio
import random
import re
import time
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple

import requests
import feedparser
import urllib.parse
from bs4 import BeautifulSoup
from aiogram import Bot
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.types import FSInputFile
from openai import OpenAI

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å Copilot SDK
try:
    from github_copilot_sdk import CopilotClient
    COPILOT_SDK_AVAILABLE = True
except ImportError:
    COPILOT_SDK_AVAILABLE = False
    print("‚ö†Ô∏è GitHub Copilot SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è OpenAI API")

# ============ CONFIG ============

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
# –í–∫–ª—é—á–∞–µ–º SDK, –µ—Å–ª–∏ –æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω
USE_COPILOT_SDK = os.getenv("USE_COPILOT_SDK", "false").lower() == "true" and COPILOT_SDK_AVAILABLE

if not all([OPENAI_API_KEY, TELEGRAM_BOT_TOKEN, CHANNEL_ID]):
    raise ValueError("‚ùå –ù–µ –≤—Å–µ ENV –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!")

bot = Bot(
    token=TELEGRAM_BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML),
)
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Copilot SDK
copilot_client = None
if USE_COPILOT_SDK:
    try:
        copilot_client = CopilotClient()
        print("‚úÖ GitHub Copilot SDK –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Copilot SDK: {e}")
        USE_COPILOT_SDK = False

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )
}

CACHE_DIR = os.getenv("CACHE_DIR", "cache")
os.makedirs(CACHE_DIR, exist_ok=True)
STATE_FILE = os.path.join(CACHE_DIR, "state.json")

RETENTION_DAYS = 14
MAX_ARTICLE_AGE_DAYS = 3
TELEGRAM_CAPTION_LIMIT = 1024

# ============ –ò–°–¢–û–ß–ù–ò–ö–ò (–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å) ============

RSS_SOURCES = [
    {"name": "SecurityLab", "url": "https://www.securitylab.ru/rss/allnews/", "category": "security"},
    {"name": "AntiMalware", "url": "https://www.anti-malware.ru/news/feed", "category": "security"},
    {"name": "Habr News", "url": "https://habr.com/ru/rss/news/?fl=ru", "category": "tech"},
    {"name": "CNews", "url": "https://www.cnews.ru/inc/rss/news.xml", "category": "tech_ru"},
    {"name": "3DNews", "url": "https://3dnews.ru/news/rss/", "category": "tech_ru"},
    {"name": "iXBT", "url": "https://www.ixbt.com/export/news.rss", "category": "tech_ru"},
]

# ============ –§–û–†–ú–ê–¢ –ü–û–°–¢–ê ============

POST_FORMAT = {
    "system": """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ü–∏—à–µ—à—å –ø–æ–Ω—è—Ç–Ω–æ –∏ –ø–æ –¥–µ–ª—É.
–¶–ï–õ–¨: –æ–±—ä—è—Å–Ω–∏—Ç—å –æ–±—ã—á–Ω—ã–º –ª—é–¥—è–º —É–≥—Ä–æ–∑—É –∏ –¥–∞—Ç—å —á–µ—Ç–∫—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é.
–ß–ò–¢–ê–¢–ï–õ–¨: –Ω–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç, –æ–±—ã—á–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–º–∞—Ä—Ç—Ñ–æ–Ω–∞.

–í–ê–ñ–ù–û:
- –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ—à–µ–Ω–∏–µ ‚Äî –ø–∏—à–∏ –ø–æ—à–∞–≥–æ–≤–æ.
- –ï—Å–ª–∏ —Ä–µ—à–µ–Ω–∏—è –Ω–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏.
- –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ.""",

    "template": """–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –¥–ª—è Telegram.

–°–ù–ê–ß–ê–õ–ê: —ç—Ç–æ –∫–∞—Å–∞–µ—Ç—Å—è –û–ë–´–ß–ù–´–• –õ–Æ–î–ï–ô? (–ï—Å–ª–∏ –ø—Ä–æ CVE/–±–∞–≥–±–∞—É–Ω—Ç–∏ –¥–ª—è –ø—Ä–æ—Ñ–∏ ‚Äî –ù–ï –ø–∏—à–∏).

–°–¢–†–£–ö–¢–£–†–ê:
‚ö†Ô∏è [–ó–ê–ì–û–õ–û–í–û–ö: —Å—É—Ç—å –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π]

**–£–≥—Ä–æ–∑–∞:**
2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è ‚Äî —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å, –≤ —á—ë–º –æ–ø–∞—Å–Ω–æ—Å—Ç—å.

**–ö–æ–≥–æ –∫–∞—Å–∞–µ—Ç—Å—è:**
–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ: –∫–∞–∫–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞/–ø—Ä–æ–≥—Ä–∞–º–º—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: "iPhone —Å iOS 16").

**–ß—Ç–æ –¥–µ–ª–∞—Ç—å:**
1. [–®–∞–≥ 1]
2. [–®–∞–≥ 2]
(–ï—Å–ª–∏ —Ä–µ—à–µ–Ω–∏—è –Ω–µ—Ç, –Ω–∞–ø–∏—à–∏ "–ñ–¥–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π").

‚è± –ó–∞–π–º—ë—Ç: [–≤—Ä–µ–º—è]

–ü–†–ê–í–ò–õ–ê:
- –û–±—ä—ë–º: 600-800 —Å–∏–º–≤–æ–ª–æ–≤
- –ë–µ–∑ —Ç–µ—Ö–Ω–∞—Ä—Å–∫–æ–≥–æ –∂–∞—Ä–≥–æ–Ω–∞
- –ó–∞–∫–æ–Ω—á–∏ –ø–æ–ª–Ω—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º"""
}

# ============ –§–ò–õ–¨–¢–†–´ ============

EXCLUDE_KEYWORDS = [
    "–∞–∫—Ü–∏–∏", "–±–∏—Ä–∂–∞", "–∏–Ω–≤–µ—Å—Ç–∏—Ü", "ipo", "–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü", "–≤—ã—Ä—É—á–∫–∞", "–ø—Ä–∏–±—ã–ª—å",
    "–Ω–∞–∑–Ω–∞—á–µ–Ω", "–æ—Ç—Å—Ç–∞–≤–∫–∞", "ceo", "hr", "–∫–∞–¥—Ä", "–ø–µ—Ä—Å–æ–Ω–∞–ª",
    "—Ñ—É—Ç–±–æ–ª", "—Ö–æ–∫–∫–µ–π", "—Å–ø–æ—Ä—Ç", "–∫–∏–Ω–æ", "—Ñ–∏–ª—å–º", "—Å–µ—Ä–∏–∞–ª",
    "–≤—ã–±–æ—Ä—ã", "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç", "–ø–æ–ª–∏—Ç–∏–∫", "—Å–∞–Ω–∫—Ü–∏–∏",
    "bitcoin", "–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç", "nft", "—Å—É–¥", "–∞—Ä–µ—Å—Ç", "–ø—Ä–∏–≥–æ–≤–æ—Ä",
    "hackerone", "bugcrowd", "bug bounty", "cvss", "cve-",
    "–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", "security researcher"
]

SOURCE_PROMO_PATTERNS = [
    r"—Å–∫–∏–¥–∫[–∞–∏]", r"–ø—Ä–æ–º–æ–∫–æ–¥", r"–∞–∫—Ü–∏—è\b", r"—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞",
    r"—Ç–æ–ª—å–∫–æ —Å–µ–≥–æ–¥–Ω—è", r"—É—Å–ø–µ–π", r"–ø—Ä–µ–¥–∑–∞–∫–∞–∑", r"—Ü–µ–Ω–∞ –æ—Ç"
]

def is_excluded(title: str, summary: str) -> bool:
    text = f"{title} {summary}".lower()
    for kw in EXCLUDE_KEYWORDS:
        if kw in text: return True
    for pattern in SOURCE_PROMO_PATTERNS:
        if re.search(pattern, text): return True
    return False

def is_security_related(title: str, summary: str) -> bool:
    text = f"{title} {summary}".lower()
    keywords = [
        "–≤–∏—Ä—É—Å", "–º–∞–ª–≤–∞—Ä", "—Ç—Ä–æ—è–Ω", "ransomware", "—à–∏—Ñ—Ä–æ–≤–∞–ª—å—â–∏–∫",
        "—Ñ–∏—à–∏–Ω–≥", "–º–æ—à–µ–Ω", "—É—Ç–µ—á–∫–∞", "–≤–∑–ª–æ–º", "—É—è–∑–≤–∏–º",
        "–≤—Ä–µ–¥–æ–Ω–æ—Å", "—à–ø–∏–æ–Ω", "—á–µ—Ä–≤—å", "—ç–∫—Å–ø–ª–æ–∏—Ç", "ddos",
        "–ø–∞—Ä–æ–ª—å", "–¥–≤—É—Ö—Ñ–∞–∫—Ç–æ—Ä", "–∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫", "—à–∏—Ñ—Ä–æ–≤–∞–Ω",
        "vpn", "–∞–Ω—Ç–∏–≤–∏—Ä—É—Å", "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å",
        "—Ç–µ–ª–µ–≥—Ä–∞–º", "whatsapp", "android", "ios", "iphone",
        "–∞–∫–∫–∞—É–Ω—Ç", "–≤–∑–ª–æ–º", "—Å–ª–µ–∂–∫", "–º–æ—à–µ–Ω–Ω"
    ]
    for kw in keywords:
        if kw in text: return True
    return False

# ============ STATE ============

class State:
    def __init__(self):
        self.data = {"posted_ids": {}, "source_index": 0}
        self._load()
    
    def _load(self):
        if os.path.exists(STATE_FILE):
            try:
                with open(STATE_FILE, "r") as f: self.data.update(json.load(f))
            except: pass
    
    def save(self):
        try:
            with open(STATE_FILE, "w") as f: json.dump(self.data, f, indent=2)
        except: pass
    
    def is_posted(self, article_id: str) -> bool:
        return article_id in self.data["posted_ids"]
    
    def mark_posted(self, article_id: str):
        self.data["posted_ids"][article_id] = {"ts": datetime.now().timestamp()}
        self.save()
    
    def cleanup_old(self):
        cutoff = datetime.now().timestamp() - (RETENTION_DAYS * 86400)
        self.data["posted_ids"] = {k: v for k, v in self.data["posted_ids"].items() if v.get("ts", 0) > cutoff}
        self.save()
    
    def get_next_source_order(self) -> List[Dict]:
        idx = self.data["source_index"] % len(RSS_SOURCES)
        ordered = RSS_SOURCES[idx:] + RSS_SOURCES[:idx]
        self.data["source_index"] = (idx + 1) % len(RSS_SOURCES)
        return ordered

state = State()

# ============ PARSING ============

def get_article_id(title: str, link: str) -> str:
    return hashlib.sha256(f"{title}|{link}".encode()).hexdigest()[:20]

def clean_text(text: str) -> str:
    if not text: return ""
    return re.sub(r'<[^>]+>', ' ', text).strip()

def fetch_full_article(url: str) -> Optional[str]:
    try:
        resp = requests.get(url, headers=HEADERS, timeout=15)
        soup = BeautifulSoup(resp.text, 'html.parser')
        for tag in soup(['script', 'style', 'nav', 'header', 'footer']): tag.decompose()
        content = soup.find('div', class_=re.compile(r'article|content|post|entry'))
        if content: return content.get_text(separator='\n', strip=True)[:4000]
    except: pass
    return None

def build_final_post(text: str, link: str) -> str:
    source = f'\n\nüîó <a href="{link}">–ò—Å—Ç–æ—á–Ω–∏–∫</a>'
    tags = "\n\n#–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å #–∫–∏–±–µ—Ä—É–≥—Ä–æ–∑—ã"
    if len(text) + len(source) + len(tags) > TELEGRAM_CAPTION_LIMIT:
        text = text[:TELEGRAM_CAPTION_LIMIT - len(source) - len(tags) - 20] + "..."
    return text + tags + source

def load_rss(source: Dict) -> List[Dict]:
    articles = []
    try:
        resp = requests.get(source["url"], headers=HEADERS, timeout=20)
        feed = feedparser.parse(resp.content)
    except: return []
    
    now = datetime.now()
    for entry in feed.entries[:30]:
        title = clean_text(entry.get("title", ""))
        link = entry.get("link", "")
        if not title or not link: continue
        
        aid = get_article_id(title, link)
        if state.is_posted(aid): continue
        
        pub_date = now
        if hasattr(entry, "published_parsed") and entry.published_parsed:
            try: pub_date = datetime(*entry.published_parsed[:6])
            except: pass
        if now - pub_date > timedelta(days=MAX_ARTICLE_AGE_DAYS): continue
        
        summary = clean_text(entry.get("summary", "") or entry.get("description", ""))
        
        if is_excluded(title, summary): continue
        if not is_security_related(title, summary): continue
        
        articles.append({
            "id": aid,
            "title": title,
            "summary": summary[:1500],
            "link": link,
            "source": source["name"],
            "date": pub_date
        })
    return articles

# ============ GENERATION ============

async def generate_post_copilot(article: Dict) -> Optional[str]:
    if not copilot_client: return None
    try:
        full_text = fetch_full_article(article["link"])
        content = full_text[:3000] if full_text else article["summary"]
        
        msg = f"{POST_FORMAT['template']}\n\n–ò–°–¢–û–ß–ù–ò–ö:\n–ó–∞–≥–æ–ª–æ–≤–æ–∫: {article['title']}\n–¢–µ–∫—Å—Ç: {content}"
        
        session = copilot_client.create_session(
            system=POST_FORMAT["system"],
            temperature=0.6,
            max_tokens=800
        )
        response = await session.send_message(msg)
        text = response.text.strip().strip('"')
        if len(text) < 100: return None
        print(f"  ‚úÖ SDK —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª: {len(text)} —Å–∏–º–≤.")
        return build_final_post(text, article["link"])
    except Exception as e:
        print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ SDK: {e}")
        return None

def generate_post_openai(article: Dict) -> Optional[str]:
    full_text = fetch_full_article(article["link"])
    content = full_text[:3000] if full_text else article["summary"]
    
    msg = f"{POST_FORMAT['template']}\n\n–ò–°–¢–û–ß–ù–ò–ö:\n–ó–∞–≥–æ–ª–æ–≤–æ–∫: {article['title']}\n–¢–µ–∫—Å—Ç: {content}"
    
    try:
        resp = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": POST_FORMAT["system"]}, {"role": "user", "content": msg}],
            temperature=0.6,
            max_tokens=800
        )
        text = resp.choices[0].message.content.strip().strip('"')
        if len(text) < 100: return None
        print(f"  ‚úÖ OpenAI —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª: {len(text)} —Å–∏–º–≤.")
        return build_final_post(text, article["link"])
    except: return None

# ============ IMAGE ============

def generate_image(title: str) -> Optional[str]:
    prompt = f"cybersecurity, hacking threat illustration, minimal style, {re.sub(r'[^a-zA-Z]', '', title)[:30]}, 4k, no text"
    url = f"https://image.pollinations.ai/prompt/{urllib.parse.quote(prompt)}?seed={random.randint(0,10**7)}&width=1024&height=1024&nologo=true"
    try:
        resp = requests.get(url, timeout=40, headers=HEADERS)
        if resp.status_code == 200 and len(resp.content) > 10000:
            fname = f"img_{int(time.time())}.jpg"
            with open(fname, "wb") as f: f.write(resp.content)
            return fname
    except: pass
    return None

def cleanup_image(path):
    if path and os.path.exists(path): os.remove(path)

# ============ MAIN ============

async def autopost():
    state.cleanup_old()
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π (Security)...")
    
    if USE_COPILOT_SDK: print("ü§ñ –†–µ–∂–∏–º: Copilot SDK")
    else: print("üîß –†–µ–∂–∏–º: OpenAI API")

    all_articles = []
    for source in state.get_next_source_order():
        all_articles.extend(load_rss(source))
    
    if not all_articles:
        print("‚ùå –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π")
        return

    all_articles.sort(key=lambda x: x["date"], reverse=True)
    
    for article in all_articles[:15]:
        print(f"\nüì∞ {article['title'][:50]}...")
        
        post_text = None
        if USE_COPILOT_SDK:
            post_text = await generate_post_copilot(article)
        
        if not post_text:
            post_text = generate_post_openai(article)
            
        if not post_text: continue
        
        img = generate_image(article["title"])
        try:
            if img: await bot.send_photo(CHANNEL_ID, photo=FSInputFile(img), caption=post_text)
            else: await bot.send_message(CHANNEL_ID, text=post_text)
            
            state.mark_posted(article["id"])
            print("‚úÖ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ!")
            cleanup_image(img)
            return
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
            cleanup_image(img)

async def main():
    try: await autopost()
    finally: await bot.session.close()

if __name__ == "__main__":
    asyncio.run(main())




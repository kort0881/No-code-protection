import os
import json
import asyncio
import random
import re
import time
import hashlib
import html
import urllib.parse
from datetime import datetime

import requests
import feedparser
from bs4 import BeautifulSoup
from youtube_transcript_api import YouTubeTranscriptApi
from aiogram import Bot
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.types import FSInputFile
from openai import OpenAI

# ============ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ============

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")

CACHE_DIR = os.getenv("CACHE_DIR", "cache_sec")
os.makedirs(CACHE_DIR, exist_ok=True)
STATE_FILE = os.path.join(CACHE_DIR, "state_smart_v3.json")

# –õ–∏–º–∏—Ç —Å–∏–º–≤–æ–ª–æ–≤, –ø–æ—Å–ª–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã –æ—Ç–∫–∞–∑—ã–≤–∞–µ–º—Å—è –æ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤ –ø–æ–ª—å–∑—É —Ç–µ–∫—Å—Ç–∞
TEXT_ONLY_THRESHOLD = 850 

# ============ –ò–°–¢–û–ß–ù–ò–ö–ò ============

RSS_SOURCES = [
    {"name": "Kaspersky Daily", "url": "https://www.kaspersky.ru/blog/feed/", "type": "rss"},
    {"name": "Kod.ru", "url": "https://kod.ru/rss/", "type": "rss"},
    {"name": "BleepingComputer", "url": "https://www.bleepingcomputer.com/feed/", "type": "rss"},
    {"name": "3DNews Soft", "url": "https://3dnews.ru/software/rss/", "type": "rss"},
    {"name": "Habr Security", "url": "https://habr.com/ru/rss/hub/infosecurity/all/?fl=ru", "type": "rss"},
    {"name": "SecurityLab", "url": "https://www.securitylab.ru/rss/news/", "type": "rss"},
]

YOUTUBE_CHANNELS = [
    {"name": "Overbafer1", "id": "UC-lHJ97lqoOGgsLFuQ8Y8_g"},
    {"name": "NetworkChuck", "id": "UC9x0AN7BWHpXyPic4IQC74Q"},
    {"name": "The Hated One", "id": "UCjr2bPAyPV7t35mVihRBCzw"},
    {"name": "NN", "id": "UCfJkM0E6qT8j6w6q5x5x_9A"},
]

# ============ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ============

bot = Bot(token=TELEGRAM_BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
openai_client = OpenAI(api_key=OPENAI_API_KEY)

class State:
    def __init__(self):
        self.data = {"posted_ids": {}, "recent_titles": []}
        self._load()
    
    def _load(self):
        if os.path.exists(STATE_FILE):
            try:
                with open(STATE_FILE, "r", encoding="utf-8") as f:
                    self.data.update(json.load(f))
                    if "recent_titles" not in self.data: self.data["recent_titles"] = []
            except: pass
    
    def save(self):
        with open(STATE_FILE, "w", encoding="utf-8") as f:
            json.dump(self.data, f, indent=2, ensure_ascii=False)
    
    def is_posted(self, uid):
        return uid in self.data["posted_ids"]
    
    def mark_posted(self, uid, title):
        if len(self.data["posted_ids"]) > 300:
            sorted_ids = sorted(self.data["posted_ids"].items(), key=lambda x: x[1])
            self.data["posted_ids"] = dict(sorted_ids[-200:])
        self.data["posted_ids"][uid] = int(time.time())
        
        self.data["recent_titles"].append(title)
        if len(self.data["recent_titles"]) > 40:
            self.data["recent_titles"] = self.data["recent_titles"][-40:]
        self.save()

    def get_recent_titles_str(self):
        return "\n".join(f"- {t}" for t in self.data["recent_titles"])

state = State()

# ============ –£–¢–ò–õ–ò–¢–´ ============

def clean_text(text):
    if not text: return ""
    text = re.sub(r'<[^>]+>', ' ', text)
    return html.unescape(text).strip()

# ============ –ü–†–û–í–ï–†–ö–ê –î–£–ë–õ–ï–ô ============

async def check_duplicate_topic(new_title):
    recent_history = state.get_recent_titles_str()
    if not recent_history: return False

    prompt = f"""–ù–∏–∂–µ —Å–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞–Ω–∞–ª–∞:
{recent_history}

–ù–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å: "{new_title}"

–í–æ–ø—Ä–æ—Å: –≠—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç –Ω–µ–¥–∞–≤–Ω–µ–π —Ç–µ–º—ã? (–†–µ—á—å –ø—Ä–æ —Ç–æ –∂–µ —Å–æ–±—ã—Ç–∏–µ?)
–û—Ç–≤–µ—Ç—å YES –∏–ª–∏ NO."""

    try:
        resp = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0, max_tokens=10
        )
        return "YES" in resp.choices[0].message.content.strip().upper()
    except: return False

# ============ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–†–¢–ò–ù–û–ö ============

def generate_creative_image_prompt(title):
    # –£–±—Ä–∞–ª–∏ –±–∞–Ω–∞–ª—å–Ω—ã–µ —â–∏—Ç—ã –∏ –∑–∞–º–∫–∏
    styles = [
        "dark cyberpunk city atmosphere, neon rain, cinematic lighting",
        "abstract data flow visualization, matrix style, green and black",
        "minimalist glitch art, distorted reality, tech noir",
        "isometric server room, stylized 3d render, soft blue lighting",
        "retro vaporwave computer aesthetic, 80s style",
        "detailed blueprint schematic, white lines on dark blue",
        "double exposure, human silhouette filled with digital code"
    ]
    
    # –û–±—ä–µ–∫—Ç—ã –±–æ–ª–µ–µ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ
    objects = [
        "digital anomaly", "broken smartphone screen", "anonymous hacker hoodie", 
        "network cables tangle", "red warning hologram", "secure usb key glowing"
    ]
    
    clean_t = re.sub(r'[^a-zA-Z0-9]', ' ', title)[:40]
    return f"{random.choice(objects)}, {clean_t}, {random.choice(styles)}, high quality 8k"

def generate_image(title):
    try:
        prompt = generate_creative_image_prompt(title)
        enc = urllib.parse.quote(prompt)
        url = f"https://image.pollinations.ai/prompt/{enc}?width=1280&height=720&nologo=true&seed={random.randint(0,99999)}"
        r = requests.get(url, timeout=20)
        if r.status_code == 200:
            path = os.path.join(CACHE_DIR, "temp_img.jpg")
            with open(path, "wb") as f: f.write(r.content)
            return path
    except: pass
    return None

# ============ –ü–ê–†–°–ï–†–´ ============

def fetch_rss(source):
    items = []
    try:
        feed = feedparser.parse(source['url'])
        for entry in feed.entries[:3]:
            uid = hashlib.md5(entry.link.encode()).hexdigest()
            if state.is_posted(uid): continue
            items.append({
                "type": "news", "title": entry.title, 
                "text": clean_text(entry.get("summary", "")),
                "link": entry.link, "source": source['name'], "uid": uid
            })
    except: pass
    return items

def fetch_youtube():
    items = []
    for channel in YOUTUBE_CHANNELS:
        try:
            feed = feedparser.parse(f"https://www.youtube.com/feeds/videos.xml?channel_id={channel['id']}")
            for entry in feed.entries[:2]:
                vid = entry.yt_videoid
                uid = f"yt_{vid}"
                if state.is_posted(uid): continue
                try:
                    transcript = YouTubeTranscriptApi.list_transcripts(vid).find_transcript(['ru', 'en']).fetch()
                    full_text = " ".join([t['text'] for t in transcript])
                    items.append({
                        "type": "video", "title": entry.title, "text": full_text[:4000],
                        "link": entry.link, "source": f"YouTube {channel['name']}", "uid": uid
                    })
                except: pass
        except: pass
    return items

# ============ GPT: –ù–ê–ü–ò–°–ê–ù–ò–ï –ü–û–°–¢–ê ============

async def process_item(item):
    if item['type'] == 'video':
        system_prompt = """–¢—ã ‚Äî –∞–≤—Ç–æ—Ä –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.
–¢–µ–±–µ –¥–∞–ª–∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –≤–∏–¥–µ–æ.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–¥–µ–ª–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä (Squeeze).
–ù–µ –ø–∏—à–∏ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π "–í —ç—Ç–æ–º –≤–∏–¥–µ–æ...". –°—Ä–∞–∑—É –∫ —Å—É—Ç–∏.
–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π —Ç–µ–∫—Å—Ç: –ó–∞–≥–æ–ª–æ–≤–æ–∫, –ü—Ä–æ–±–ª–µ–º–∞, –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏, –†–µ—à–µ–Ω–∏–µ."""
    else:
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π (–£–°–ò–õ–ï–ù–ù–´–ô)
        system_prompt = """–¢—ã ‚Äî –≤–µ–¥—É—â–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –Ω–∞–ø–∏—Å–∞—Ç—å –≥–ª—É–±–æ–∫–∏–π, –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ—Å—Ç –¥–ª—è –∫–∞–Ω–∞–ª–∞.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ï—Å–ª–∏ –∏—Å—Ö–æ–¥–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å –∫–æ—Ä–æ—Ç–∫–∞—è ‚Äî –†–ê–°–®–ò–†–¨ –µ—ë, –∏—Å–ø–æ–ª—å–∑—É—è —Å–≤–æ–∏ –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ. –û–±—ä—è—Å–Ω–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Å—É—Ç—å —É–≥—Ä–æ–∑—ã.
2. –ò–∑–±–µ–≥–∞–π –±–∞–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π ("–±—É–¥—å—Ç–µ –±–¥–∏—Ç–µ–ª—å–Ω—ã", "–Ω–µ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –ø–æ —Å—Å—ã–ª–∫–∞–º"). –î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (–∫–∞–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–∫–ª—é—á–∏—Ç—å, –∫–∞–∫–æ–π —Å–æ—Ñ—Ç –ø—Ä–æ–≤–µ—Ä–∏—Ç—å).
3. –°—Ç–∏–ª—å: –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, –Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–π. –ë–µ–∑ "–¥–µ—Ç—Å–∫–æ–≥–æ —Å–∞–¥–∞" –∏ –ª–∏—à–Ω–∏—Ö —ç–º–æ–¥–∑–∏.
4. –ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å –ø—Ä–æ –±–∏–∑–Ω–µ—Å/–æ—Ç—á–µ—Ç—ã/–Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è ‚Äî –≤–µ—Ä–Ω–∏ SKIP.

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ—Å—Ç–∞:
üî• [–¶–µ–ø–ª—è—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫]

[–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç: —Å—É—Ç—å –ø—Ä–æ–±–ª–µ–º—ã, –∫–æ–≥–æ –∫–∞—Å–∞–µ—Ç—Å—è, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏]

üëá –ß–¢–û –î–ï–õ–ê–¢–¨:
‚Ä¢ [–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–æ–≤–µ—Ç 1]
‚Ä¢ [–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–æ–≤–µ—Ç 2]
"""

    try:
        resp = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Title: {item['title']}\n\nText: {item['text']}"}
            ],
            max_tokens=1500 # –†–∞–∑—Ä–µ—à–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        )
        text = resp.choices[0].message.content.strip()
        if "SKIP" in text or len(text) < 50: return None
        return text + f"\n\nüîó <a href='{item['link']}'>–ò—Å—Ç–æ—á–Ω–∏–∫</a>"
    except Exception as e:
        print(f"AI Error: {e}")
        return None

# ============ MAIN ============

async def main():
    print("üöÄ Start scan...")
    all_items = []
    all_items.extend(fetch_youtube())
    for src in RSS_SOURCES:
        all_items.extend(fetch_rss(src))
    
    random.shuffle(all_items)
    print(f"üì¶ Candidates: {len(all_items)}")

    for item in all_items:
        print(f"üîç Analyzing: {item['title']}")
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–µ–π
        if await check_duplicate_topic(item['title']):
            print(f"   üö´ DUPLICATE TOPIC. Skipping.")
            state.mark_posted(item['uid'], item['title'])
            continue

        # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
        post_text = await process_item(item)
        
        if post_text:
            text_len = len(post_text)
            print(f"   ‚úÖ Post ready. Length: {text_len} chars.")
            
            # 3. –†–µ—à–µ–Ω–∏–µ: –ö–∞—Ä—Ç–∏–Ω–∫–∞ –∏–ª–∏ –¢–µ–∫—Å—Ç?
            # –ï—Å–ª–∏ –ø–æ—Å—Ç –¥–ª–∏–Ω–Ω—ã–π (>850 —Å–∏–º–≤–æ–ª–æ–≤), –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ë–ï–ó –∫–∞—Ä—Ç–∏–Ω–∫–∏, —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å —Ç–µ–∫—Å—Ç
            if text_len > TEXT_ONLY_THRESHOLD:
                print("   üìú Long read detected. Sending TEXT ONLY.")
                try:
                    await bot.send_message(CHANNEL_ID, text=post_text, disable_web_page_preview=False)
                    print("   üéâ Posted text!")
                    state.mark_posted(item['uid'], item['title'])
                    break
                except Exception as e:
                    print(f"‚ùå Telegram Error: {e}")
            
            # –ï—Å–ª–∏ –ø–æ—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π, –¥–µ–ª–∞–µ–º –∫—Ä–∞—Å–∏–≤—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É
            else:
                print("   üì∏ Short read. Generating IMAGE.")
                img_path = generate_image(item['title'])
                try:
                    if img_path:
                        await bot.send_photo(CHANNEL_ID, photo=FSInputFile(img_path), caption=post_text)
                        os.remove(img_path)
                    else:
                        await bot.send_message(CHANNEL_ID, text=post_text)
                    
                    print("   üéâ Posted with image!")
                    state.mark_posted(item['uid'], item['title'])
                    break
                except Exception as e:
                    print(f"‚ùå Telegram Error: {e}")

        else:
            state.mark_posted(item['uid'], item['title'])

    await bot.session.close()

if __name__ == "__main__":
    asyncio.run(main())
